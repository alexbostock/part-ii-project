\documentclass[12pt,a4paper]{article}
\usepackage{fullpage}
\usepackage{fancyhdr} %headers
\usepackage{titlesec}
\usepackage{graphicx} %images
\usepackage{amsmath} %maths
\usepackage{amssymb} %maths symbols
\usepackage{subfig}
\usepackage[section]{placeins}
\usepackage{listings}
\usepackage[T1]{fontenc}
\usepackage{lastpage}

\usepackage{enumerate}

\usepackage{braket}

\renewcommand{\headrulewidth}{0pt}

\nonstopmode

\setlength{\headheight}{15pt}

\graphicspath{ {img/} }

%\titleformat{name=\section}
%  {\normalfont\scshape}{\thesection}{1em}{\large}

\titleformat{name=\section}
  {\normalfont\large\scshape}{\thesection}{1em}{}

\titleformat{name=\subsection}
    {\normalfont\normalsize}{\thesubsection}{1em}{\large}

%%\titleformat{\subsubsection}
%  {\normalfont\normalsize}{\thesubsubsection}{1em}{}

\setlength{\parindent}{0em}
\addtolength{\parskip}{1ex}

\lstset{
	basicstyle=\scriptsize,
	breaklines=true
}

\pagestyle{fancy}
\setlength{\headsep}{0.2in}
\title{Part II Project: Design Specification}
\author{Alex Bostock}

\date{}
\fancyhf{}
%\lhead{Summer Work IB/II}
%\rhead{atb46}

\cfoot{\thepage / \pageref{LastPage}}

\begin{document}
\maketitle
\thispagestyle{fancy}

\section*{Introduction}

This document describes what I will implement. This includes 3 components:

\begin{itemize}
  \item
  A strongly consistent, distributed key-value store based on quorum assembly.

  \item
  An eventually-consistent variant of that system, based on sloppy quorum, which sacrifices strong consistency for better availability.

  \item
  A test framework to interface with the database systems, simulating a network of distributed database nodes on one machine, so that my systems can be evaluated in a controlled environment.

\end{itemize}

The database systems will be optimised for web applications such as social networks, in which the vast majority of database transactions are reads, with a much smaller number of write operations.

\section*{Public Interface}

My database will offer two public methods:

\begin{itemize}
  \item
  \verb|put(key, value)| should either store the given key and value in the system, or error. This method can also be used to delete a value from the datastore, by putting a null value for the relevant key.

  \item
  \verb|get(key)| should return a value from the store, which is associated with the given key. In the strongly consistent variant of the system, this must always be the most recently put value for that key. In the eventually consistent variant, this may be any value which has been previously put. After an indefinite amount of time without writes, the eventually consistent variant should serve the most recent value, and the time to reach consistency should be minimised.

\end{itemize}

All keys and values are byte arrays, so the type and structure of data is irrelevant to the database system. Keys and values may not contain the null character, since this will be used internally in the datastore.

The database system is distributed across many nodes. Each node is the same, so any can process a transaction for an external client. In the real world, this would mean that a client could send a transaction to the geographically closest database node, or choose any alternative node in case the nearest node fails.

\subsection*{Remote Procedure Calls}

For distributed systems, in general, clients making requests are not directly connected; they can only communicate using an unreliable network. Given this limitation, some system is needed to encapsulate procedure calls. Such systems are often based on hypertext transfer protocol (HTTP), due to its wide usage on the Internet.

One method is representational state transfer (REST), which is based on the concept of resources. The URL should contain the name of a resource, and the type of operation should be indicated by the HTTP verb (GET, POST, PUT etc.) used. This works well with create, read, update and delete (CRUD) operations which are meaningful in database systems.

One drawback of REST is its inefficiency. Suppose we have 4 types of operations. The information conveyed by specifying the type of operation is 2 bits. The HTTP verb GET uses 3 bytes, so is a very inefficient encoding.

Instead, we can use an RPC library which is not based on text encoding. RPC libraries can also provide significant abstractions, so that RPC calls are very similar to normal function calls, from the client's point of view. For example, Java's remote method invocation system provides an abstraction over serialising and deserialising Java objects, and providing distributed garbage collection.

For this project, I will not use any RPC solution which would be used in a real deployment. Since I am going to run the whole system on a single machine, I can use a much simpler mechanism. HTTP (using transmission control protocol, TCP) provides support for (mostly) reliable communication over unreliable networks, using checksums and re-transmission. On a single machine, I will have a reliable simulated network, so TCP is unnecessary, and would add additional complexity and latency to the system.

In order to evaluate my system, I need to be able to add variable latency and packet loss to simulate different network conditions. By minimising the latency of my RPC service, there will be minimal noise affecting my measurements.

\section*{System Overview}

My system will be built so that it interfaces closely with my test framework, using my RPC system. This will provide an ideal environment for integration testing and evaluating the system's performance. The architecture is based on two of Go's concurrency primitives: goroutines and channels.

Goroutines are similar to threads. Rather than using OS-level scheduling, the Go runtime has its own scheduler. Goroutines, unlike normal threads, have dynamically-sized stacks. Typically, threads have a stack size around 1MB. This means that the number of active threads is limited by memory usage. Using a smaller stack allows more threads, but limits the number of stack frames before a stack overflow error. Using dynamically-sized stacks, the number of active goroutines can be much larger.

Channels in Go are essentially thread-safe queue structures. These are ideal for producer-consumer patterns. Consumers can easily poll the queue, blocking until a value is available. My design uses channels to simulate network links.

Each database node will run as its own goroutine. The system will support a fixed number of nodes, so each node will be identified by a unique integer. These will be assigned sequentially and remain constant, so they can be used as addresses in the simulated network.

For each database node, there will be two channels: one for incoming messages, and one for outgoing messages. A message may be a request from a (simulated) external client, a response to such a request, or a message used to coordinate nodes in the system. A message has 3 fields: source and destination addresses (integers), and a payload, the structure of which depends on the type of message. In order to handle a message, the network simulator only needs to inspect the source and destination addresses.

Supporting each database node, there will be an additional goroutine responsible for delivering its outgoing messages. This will use the following algorithm:

\begin{lstlisting}
while true:
    message = outgoingMessages.poll() // Blocking deque

    // Simulate failed nodes by dropping all their packets
    if (destination node has failed):
        continue

    // Random latency
    delay = a random value, simulating the latency of tcp given some parameters
    sendAfterDelay(message, delay)
\end{lstlisting}

The \verb|sendAfterDelay| method spawns a new goroutine, which sleeps for the given time, then appends the message to the recipient's incoming queue. This means that the main loop will not block, so later messages will be delivered without uncontrolled delay.

The main routine will be responsible for simulating clients. This includes generating requests, sending these requests to random database nodes, and recording responses. For each request, it should record the time from request to response (if a response was received). If a request times out without a response, this should also be recorded.

Once all requests have either timed out or been responded to, the main routine will terminate (thus halting the whole system). By configuring the number and type of tests and recording responses (as well as configuring the network properties, as described above), this can be used for both integration testing and evaluating the system's performance.

% TODO: diagram

\section*{Key Components}

\subsection*{Data Storage}

Each database node in the system needs its own key-value store. This will be built as a module independently of all distributed components of the system, and can be tested as a stand-alone module. Since the main focus of this project is distributed systems, and I expect the performance bottleneck to be network latency, this module is designed preferring simplicity over optimisation. As an extension, I may explore more efficient data structures for storage.

The datastore is built on top of a Unix-like file system. The particular file system does not matter, provided modification to a file descriptor (eg. renaming a file) is an atomic operation.

Data will be stored as binary files. The interface says that keys and values are byte arrays, which may not contain the null character. Keys and values will be written to disk as binary, using the null character (\verb|\0|) as a delimiter. The content of any valid file will match the format:

\verb|(Key \0 Value \0)*|

Also, a file must contain at most one occurrence of any key. Given this, any file can be uniquely deserialised to a map from byte array to byte array.

There is no requirement for any ordering of keys in a file, so the most efficient way to lookup a key is a linear search, which will take $O(n)$ time when there are $n$ key-value pairs stored. To mitigate this, data will be split between multiple files, based on a hash of the key.

A simple hash function could use the prefix of the key: the first 2 bytes, for example. This would divide data uniformly if keys are random, but may group many values together if their keys are similar (which is entirely determined by the application programmer).

Instead, I will use MD5. While not cryptographically secure, MD5 is a relatively fast hashing algorithm. Each file in the datastore will correspond to the first 2 bytes of an MD5 hash. This should divide data uniformly, assuming that keys are not chosen with intent to maximise the number of collisions. The name of each file will be the 2 byte prefix, encoding as a hexadecimal string to avoid use of invalid characters in filenames. This will also not require the filenames to be case sensitive in the underlying file system.

The most important method for the datastore to provide is atomic writes. This is achieved by writing to a shadow data structure.

My system does not allow concurrent write transactions, and each write modifies 1 key-value pair. This means that each transaction modifies one data file, and all writes are sequential. The write procedure for modifying a file $f$ is:

\begin{itemize}
  \item
  Create a new file $g$.

  \item
  Write data to $g$, which will be the contents of $f$, modified based on the transaction's parameters.

  \item
  Wait for a commit instruction.

  \item
  If a commit instruction is received, change the file descriptor $f$ to point at $g$ (\verb|mv g f|).

  \item
  If, instead, a rollback instruction is received, delete $g$.

\end{itemize}

\subsection*{Quorum Assembly}

The main method for ensuring consistency in my system is quorum assembly. For a strongly consistent system, strict quorum assembly is needed. For eventual consistency, this will be modified to use a sloppy quorum method.

Given a system of $n$ nodes, we first have to define two values $V_R$ and $V_W$, which are the sizes of read and write quorums, respectively. At least $V_R$ nodes must be involved in every read transaction, and at least $V_W$ nodes must be involved in every write. In a strict quorum system, we also enforce the following constraints:

$$V_W > n / 2$$

$$V_R + V_W > n$$

The first constraint means that every value written to the database must be written to a majority of database nodes. The second constraint means that, for any read quorum, at least one node in the quorum will have the most recent version of each value stored. Where multiple conflicting values exist for the same key, we need Lamport timestamps to identify the most recent value.

Lamport timestamps are monotonically increasing integers, which indicate the order in which some events occur. If some event $A$'s timestamp is smaller than another event $B$'s, then $A$ happened before $B$.

In my system, each node stores a Lamport timestamp for each database key. Where different nodes have conflicting values for the same key, the one with the greater clock value is most recent.

In order to ensure Lamport clock values do not overflow, and thus to ensure they are monotonically increasing, my system will use 64 bit unsigned integers for Lamport clocks. A clock value is incremented each time the associated key-value pair is overwritten. Assuming a high throughput, with 1 transaction every 10 milliseconds writing to the same key, the time before the Lamport clock overflows will be $2^{64} \times 10 \cdot 10^{-3} = 1.84 \cdot 10^{16} \text{seconds}$. This is more than 5 billion years, so 64 bit timestamps should be adequate.

Building on the basic data store interface, Lamport clock values will be stored as part of the value. At the lower level, each value is actually the concatenation of a Lamport timestamp and the data being stored. In the case when a value is deleted, the concatenation of a timestamp and an empty byte array will be stored. This indicates that a value has been deleted from this node, which will be necessary for reads (for example, when a read quorum contains some nodes on which a value has been deleted, and some which still have a stale value), but does not violate the requirement of not storing null values in the low-level store.

The procedure for a read transaction is:

\begin{itemize}
  \item
  A node receives a read request from the client. This node shall be the coordinator.

  \item
  Assemble a quorum of at least $V_R$ nodes, and obtain a lock on each node in the quorum.

  \item
  The coordinator queries each node in the quorum with the given key.

  \item
  Each node returns the value it has stored, and the Lamport clock associated with the key, or says it has no value stored for the key.

  \item
  The coordinator identifies the value with the highest Lamport timestamp, and returns that value as the result.

  \item
  The coordinator releases all locks.

\end{itemize}

Note that this may reach a deadlock condition. Suppose there are multiple concurrent transactions, concurrently acquiring locks on nodes. This may reach a condition where every node is locked, but no coordinator has assembled a complete quorum.

There will also be a problem if the coordinator fails before it releases locks. This would leave nodes permanently locked, and effectively useless.

To fix both of these problems, each node should set a timer when its lock is acquired, and reset that timer each time it responds to a request from the coordinator. If the timer runs out, it should release its lock. If it subsequently receives a request from the coordinator, it should return an error. The coordinator, if it receives an error, should abort and retry the transaction.

Note that, since every node in a read quorum is locked, and given the constraint $V_R + V_W > n$, there cannot be concurrent read and write transactions. This imposes a happens-before relationship between each read transaction and every write transaction, so ensures that the value read is consistent. There may be concurrent read transactions; this has no effect on consistency, and will allow greater throughput.

The procedure for write transactions is similar to that for reads, but requires additional work to ensure atomicity. When a value is written, it must be either written to a full write quorum, or not written at all. This is achieved using an atomic commit protocol, 2 phase commit (2PC).

The write procedure is:

\begin{itemize}
  \item
  A node receives a write request from the client. This node shall be the coordinator.

  \item
  Assemble a quorum of at least $V_W$ nodes, and obtain a lock on each node in the quorum.

  \item
  The coordinator queries the existing value for the required key from each node in the quorum. Note that this is essentially a read transaction before a write transaction, which is why strict quorum is sometimes describe as ``read your own writes''

  \item
  Each node returns the value it has stored for the given key, and the Lamport clock associated with that key.

  \item
  The coordinator identifies the most recent timestamp associated with the key. Note that, given the constraint $V_W > n / 2$, this must be the most recent write for the key. The coordinator increments the greatest timestamp to get the timestamp for the new write.

  \item
  The coordinator initiates 2PC with all the nodes in the quorum, to write the new value and the new Lamport timestamp.

  \item
  The coordinator releases all locks.

\end{itemize}

The same deadlock condition as with read transactions applies here, so we will use the same timer system for pre-emption.

\subsection*{Two-Phase Commit (2PC)}

In 2PC, the coordinator begins by sending the transaction to each node in the quorum, as well as sending a list of nodes involved in the transaction.

Each node should then execute the transaction, writing the new value to persistent storage but not yet committing. It should save a new vector clock value with the new value, which is the merge of its existing vector for the key, and the vector clock from the coordinator. It should then respond to the coordinator with a yes vote, and a copy of its new vector clock for the key. In case of any failure, it should respond with a no vote, and can cancel the transaction.

If the coordinator receives a yes vote from every node, it should:

\begin{itemize}
  \item
  Send a commit message to each node.

  \item
  Wait for an acknowledgement from each node.

  \item
  When it receives an acknowledgement from every node, commit the transaction to its own disk.

\end{itemize}

In the case that the coordinator does not receive an acknowledgement from every node, it should repeatedly send commit messages until it does so. This is one drawback of 2PC: it is a blocking protocol. Until all nodes involved have acknowledged, a write transaction cannot be completed. Note that all nodes involved are locked throughout this time; given that concurrent writes are not allowed, this will affect the availability of the system, but it does provide consistency.

If the coordinator doesn't receive a yes vote from every node (either at least one no vote, or a response times out), it should send a rollback message to all nodes.

In case of the coordinator failing, all other nodes in the transaction will timeout. In this case, since they all know the identifiers of all nodes involved in the transaction, the node with the lowest identifier becomes a new coordinator. The new coordinator queries all other nodes for their votes. In case any node voted no, it should be aborted. Otherwise, the transaction can be completed. When the coordinator recovers, it can determine from the other nodes whether or not the transaction was committed.

2PC is tolerant of most failure scenarios.

\begin{itemize}
  \item
  In the case of a node (or several nodes) other than the coordinator failing before sending a yes vote, the coordinator will abort the transaction.

  \item
  In the case of a node other than the coordinator failing after sending a yes vote, the failed transaction will be stored persistently on that node, so the node will be able to recover.

  \item
  In the case of the coordinator failing, all other nodes involved in the transaction can communicate to decide whether or not to abort. The transaction will be stored persistently on the coordinator node, so the coordinator can recover in the same way as any other node failing after voting yes.

\end{itemize}

A limitation of this is that it is not tolerant of data loss on failure, for example due to disk failure. This is a limitation of my system. In the real world, each node could store data on multiple disks in a RAID array, making the chance of data loss negligible. In case of total loss of database nodes, data could still be recovered provided at least half of the database nodes are unaffected, although at the cost of availability.

Another issue is the case of simultaneous failure of both the coordinator and another node. In this case, the remaining nodes could try to recover, but could not know whether the second failed node voted yes or no. This is a limitation of my system. As an extension, I may modify the system to use three-phase commit (3PC), which addresses this problem.

\subsection*{Sloppy Quorum}

Sloppy quorum is a modification to the strict quorum system, which does not provide strong consistency guarantees. The procedure for transactions is the same as before, but we remove the constraint $V_R + V_W > n$.

This means that a read transaction may not return the most recent value for the requested key; it may return a stale value. The benefit is that more read transactions can occur concurrently, which will allow a greater throughput of transactions, and the system can remain available for read after a larger number of node failures: as long as at least $V_R$ nodes are available, read transactions can still occur.

In order to provide eventual consistency, we need to change the system more. In an eventually consistent system, if there are no write transactions, the whole system should reach a consistent state after some amount of time. This means that every read transaction should eventually return the most recently written value for each key. Having removed the constraint on $V_R$, this means that values should eventually be written to at least $n - V_R + 1$ nodes.

In order to achieve this, I will add an additional mechanism for sharing values between database nodes. Each write transaction has a coordinator, and that coordinator will be responsible for ultimately propagating the write to at least $n - V_R + 1$ nodes. My system assumes that the set of nodes is fixed, and there is no requirement for the time to reach consistency, so the coordinator can resume this task after failure and recovery without issue.

For each database key, each node should store an integer $x$ representing the number of nodes which have definitely received the value stored.  When a value is written by a transaction coordinated by another node, that value's $x$ can be set to $n$; although not true, the propagation of that value is another node's responsibility. When a node coordinates a write transaction, it should set $x$ to the number of nodes in the write quorum.

Each node then needs a background process to continually propagate values for which $x$ is smaller than $n - V_R + 1$. This could be done by initiating write transaction, but doing so would take much more time, and the consistency guarantee is not required.

Instead, a node can send a lightweight write message to other nodes. When a lightweight write message is received, a node should compare the given key, value and timestamp to what it has stored. If the value received is more recent than that stored, it should update its stored value and reply. Otherwise, it should reply with its more recent value and timestamp. When receiving a response from a lightweight write, a node can either increment $x$ for the relevant key, or store a more recent value in its store.

In case of failure of a lightweight write, there is no problem. The guarantees provided by full write transactions are still the same, and lightweight transactions can be retried later to eventually achieve consistency.

\subsection*{Concurrent Writes}

As with the strongly consistent variant, my eventually consistent design does not allow concurrent write transactions. This is enforced with the constraint $V_W > n / 2$. In order to further increase throughput, we could allow concurrent writes, but this would reduce the consistency guarantee.

With eventually consistency, we want the last write to persist. This means that we need to impose a total ordering on write operations. With my design, it is guaranteed that two values for the same key with the same Lamport timestamp will be the same. By allowing concurrent writes, this would not be the case. There are several solutions to this:

\begin{itemize}
  \item
  Use UTC timestamps rather than logical clocks. While this solution may be acceptable for some applications, it does not work in general. An important limitation of distributed systems is that there is no common clock across the whole system. Network time protocol (NTP) allows synchronisation of clocks across to within some error margin (depending on network conditions), but this would not help to order two transaction which happened within the error margin, so is not useful as a general solution.

  \item
  Store multiple values for the same key where conflicts occur. This solution is effectively passing the problem to application developers instead. At the cost of storing multiple values for the same key, we can provide the client with conflicting values and their timestamps. With this solution, Lamport timestamps are not very useful, since they do not show causality between concurrent events.

  To improve on Lamport clocks, vector clocks can be used. Vector clocks contain a Lamport timestamp for each node in the system. They show exactly which previous transactions may have affected a transaction, across the whole system. For example, a client may know which node handled a previous transaction, and vector clocks would make it clear which of several conflicting values would be consistent with that previous transaction, at the application level.

  I may explore this method as an extension.

\end{itemize}

\section*{System Limitations}

My design has a number of important limitations, which are summarised here.

\begin{itemize}
  \item
  The set of database nodes is fixed. Additional nodes cannot be added to the system, and existing ones cannot be removed. In practice, the ability to change the set of nodes is useful for scaling a system while it is running, but doing so adds more complexity. Quorum assembly relies on the values $V_R$ and $V_W$, and their constraints which depend on the number of nodes $n$, so the number of nodes cannot be changed dynamically.

  \item
  Nodes cannot fail permanently. In 2PC, if a node fails, we need to wait for that node to become available again before allowing further writes, to ensure that the system remains consistent.

  \item
  The system may not remain consistent if, during a 2PC transaction, both the coordinator and another node in the quorum fail.

  \item
  If any database node's persistent store is irreversibly corrupted on failure, then consistency guarantees may be violated.

\end{itemize}

\end{document}

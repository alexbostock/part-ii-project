% Template for a Computer Science Tripos Part II project dissertation
\documentclass[12pt,a4paper,twoside,openright]{report}
\usepackage[pdfborder={0 0 0}]{hyperref}    % turns references into hyperlinks
\usepackage[margin=25mm]{geometry}  % adjusts page layout
\usepackage{graphicx}  % allows inclusion of PDF, PNG and JPG images
\usepackage{verbatim}
\usepackage{docmute}   % only needed to allow inclusion of proposal.tex
\usepackage{makecell}
\usepackage{amsmath}
\usepackage{listings}

\raggedbottom                           % try to avoid widows and orphans
\sloppy
\clubpenalty1000%
\widowpenalty1000%

\renewcommand{\baselinestretch}{1.1}    % adjust line spacing to make
                                        % more readable

\begin{document}

\bibliographystyle{plain}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Title


\pagestyle{empty}

\rightline{\LARGE \textbf{Alex Bostock}}

\vspace*{60mm}
\begin{center}
\Huge
\textbf{A Comparison of Consistency Models in Distributed Database Systems} \\[5mm]
Computer Science Tripos -- Part II \\[5mm]
Churchill College \\[5mm]
\today  % today's date
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Proforma, table of contents and list of figures

\pagestyle{plain}

\chapter*{Proforma}

{\large
\begin{tabular}{ll}
Name:               & \bf Alex Bostock                          \\
College:            & \bf Churchill College                     \\
Project Title:      & \makecell[tl]{\bf A Comparison of Consistency Models in \\ \bf Distributed Database Systems}\\
Examination:        & \bf Computer Science Tripos -- Part II, July 2019  \\
Word Count:         & \bf 0  \\
Project Originator: & A. T. Bostock                    \\
Supervisor:         & Dr J. K. Fawcett                    \\ 
\end{tabular}
}
\stepcounter{footnote}


\section*{Original Aims of the Project}

TODO

\section*{Work Completed}

TODO

\section*{Special Difficulties}

TODO
 
\newpage
\section*{Declaration}

I, [Name] of [College], being a candidate for Part II of the Computer
Science Tripos [or the Diploma in Computer Science], hereby declare
that this dissertation and the work described in it are my own work,
unaided except as may be specified below, and that the dissertation
does not contain material that has already been used to any substantial
extent for a comparable purpose.

\bigskip
\leftline{Signed [signature]}

\medskip
\leftline{Date [date]}

\tableofcontents

\listoffigures

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% now for the chapters

\pagestyle{headings}

\chapter{Introduction}

% TODO: Make it clear in the first paragraph what your project is about \& how well youâ€™ve done it

- Why distributed databases? \cite{bacon2003operating}

With a single database server, we have an availability problem (no transactions when the server fails or cannot be reached) and a consistency problem (data loss if the server is destroyed). Use a distributed system with many database nodes to reduce the risk of a total failure, but this means consistency is more difficult to achieve.

- CAP theorem \cite{brewer} \cite{gilbert}

Brewer proposed a system can have at most 2 of consistency, availability, partition-tolerance \cite{brewer}. Informal definitions. Partition-tolerance means that a system continues to work in the presence of network partitions. Consistency means guarantees about clients' reads and writes. Availability means ability to execute transactions.

Using particular strict definitions, \cite{gilbert} proved the CAP theorem. This assumes consistency is strong consistency (linearisability) and availability means the database can complete transactions whenever at least one node is alive. Very few real world applications have either consistency or availability by these definitions.

This doesn't consider different types of consistency, especially eventual consistency and other models from \cite{terry2013}. Also, consider availability as non-boolean. Instead, consider availability to mean DQ (harvest and yield). In addition, note that we can't choose not to have partition-tolerance in an Internet-scale application. \cite{hale_2010}

Even with availability, latency is also important. Instead of CAP, PACELC: in the presence of partitions, trade-off of consistency and availability, else trade-off of latency and consistency. \cite{abadi2012consistency}

My project explores what availability and latency can be achieved while providing different consistency guarantees.

- Use case: social network

Interested in databases for large web applications such as social networks. Key points:

\begin{itemize}
\item
Mostly reads (95\%) \cite{nunemaker}

\item
Availability is important (for revenue) (https://developers.google.com/web/fundamentals/performance/why-performance-matters/)

\item
Consistency is important, but not critical. Don't need to make a tweet visible everywhere immediately, but do want to optimise convergence time. Serving something is more important than serving the most recent data (but both is nice).

\end{itemize}

\chapter{Preparation}
% 26% (with intro)

%From design doc, with what has changed since then:

%- Public interface, specific consistency guarantees (session guarantees)

%  - Semantics of no value stored / no value found / no response

%  - Semantics of overwriting old values, alternatives (larger atomic transactions), usefulness to applications

\section{Public Interface}

I built a distributed database system which provides several different consistency guarantees. This system is a key-value store, storing values indexed by keys. The client interface provides 2 methods:

\begin{itemize}
\item
\verb|put(key, value)| either stores the given key and value in the system, or returns an error. This can also be used to delete a value, by storing the null value. If the transaction was completed successfully, put also returns a unique timestamp associated with the value stored.

\item
\verb|get(key)| either returns a value associated with the given key and that value's timestamp, or returns an error response.

\end{itemize}

A put request has 3 possible response values: success (and a timestamp), failure and unknown. This reflects a limitation of distributed systems: there is no guarantee that a response will be received.

If no response is received, there is no way to determine whether or not the transaction was completed. This case is represented by the unknown response value. Each request has at-most-once semantics; wherever possible, the return value indicates whether or not a transaction was completed.

Calls to get are idempotent: they do not modify any data. The only goal of a get is to return a value to the client. If no response is received, this was failed, so this case is identical to receiving an error response from the client's point of view. Note that get may return a null value, indicating that no value is stored associated with the given key. Importantly, a null response (value not present) is different from an error response (transaction failed).

All keys and values can be byte arrays of any size. The database does not inspect their values, so the type and structure of data stored is irrelevant.

Put requests do not read any current value stored, except for timestamps. This means the system cannot be reliably used for larger atomic operations (without using some external locking system). % TODO: implement and change here

\section{Remote Procedure Calls}

% Copies from design document
% TODO: cut this down

For distributed systems, in general, clients making requests are not directly connected;
 they can only communicate using an unreliable network. Given this limitation, some syst
em is needed to encapsulate procedure calls. Such systems are often based on hypertext t
ransfer protocol (HTTP), due to its wide usage on the Internet.

One method is representational state transfer (REST), which is based on the concept of r
esources. The URL should contain the name of a resource, and the type of operation shoul
d be indicated by the HTTP verb (GET, POST, PUT etc.) used. This works well with create, read, update and delete (CRUD) operations which are meaningful in database systems.

One drawback of REST is its inefficiency. Suppose we have 4 types of operations. The information conveyed by specifying the type of operation is 2 bits. The HTTP verb GET uses 3 bytes, so is a very inefficient encoding.

Instead, we can use an RPC library which is not based on text encoding. RPC libraries can also provide significant abstractions, so that RPC calls are very similar to normal function calls, from the client's point of view. For example, Java's remote method invocation system provides an abstraction over serialising and deserialising Java objects, and providing distributed garbage collection.

For this project, I will not use any RPC solution which would be used in a real deployment. Since I am going to run the whole system on a single machine, I can use a much simpler mechanism. HTTP (using transmission control protocol, TCP) provides support for (mostly) reliable communication over unreliable networks, using checksums and re-transmission. On a single machine, I will have a reliable simulated network, so TCP is unnecessary, and would add additional complexity and latency to the system.

In order to evaluate my system, I need to be able to add variable latency and packet loss to simulate different network conditions. By minimising the latency of my RPC service, there will be minimal noise affecting my measurements.

\section{Quorum Assembly}

My system uses quorum assembly to enforce consistency. For strong consistency, we use a strict quorum system.

Assume the system has $n$ database nodes. Define 2 parameters $V_R$ and $V_W$, which satisfy the following conditions:

$$V_W > n / 2$$

$$V_R + V_W > n$$

$V_W$ is the number of nodes required for a write transaction. The first condition means that every write sees every other write: each write involves more than $n/2$ nodes chosen fromt he same set of $n$, so there must be at least 1 node involved in both transactions. This ensures that every write to a particular key will have a unique timestamp, so there is a unique ordering of write transactions.

The first condition also means that, once a write has been committed, there are at more than $n/2$ copies of the value written, so no data will be lost in the event of total failure of any $n/2$ database nodes.

$V_R$ is the number of nodes required for a read transaction. The second condition means that every read sees every write. Since conflicting values for the same key must have unique timestamps, every read will always return the most recent value, satisfying the conditions for strong consistency. % TODO: make sure strong consistency is defined before this point

\section{Sloppy Quorum}

If strong consistency is not required, we can use a quorum system with more relaxed constraints. We can achieve different performance and different consistency guarantees by imposing different constraints. Consider removing each from a strict quorum system.

\begin{tabular}{| p{0.4\linewidth} | p{0.5\linewidth} |}
\hline
$V_W > n / 2$ and $V_R + V_W > n$ & Strong consistency.\\
\hline
Only $V_W > n / 2$ & Monotonic writes, may read stale values, can be made eventually consistent.\\
\hline
Only $V_R + V_W > n$ & Write conflicts, optimised for writes.\\
\hline
No constraints & Write conflicts, may read stale values, but (I expect) best availability.\\
\hline
\end{tabular}

I implemented the first 2. % TODO: implement more and add that here

- Example uses for each of the above

\section{Concurrent Writes}

As with the strongly consistent variant, my eventually consistent design does not allow concurrent write transactions. This is enforced with the constraint $V_W > n / 2$. In order to further increase throughput, we could allow concurrent writes, but this would reduce the consistency guarantee.

With eventually consistency, we want the last write to persist. This means that we need to impose a total ordering on write operations. With my design, it is guaranteed that two values for the same key with the same Lamport timestamp will be the same. By allowing concurrent writes, this would not be the case. There are several solutions to this:

\begin{itemize}
\item
Use UTC timestamps rather than logical clocks. While this solution may be acceptable for some applications, it does not work in general. An important limitation of distributed systems is that there is no common clock across the whole system. Network time protocol (NTP) allows synchronisation of clocks across to within some error margin (depending on network conditions), but this would not help to order two transaction which happened within the error margin, so is not useful as a general solution.

\item
Store multiple values for the same key where conflicts occur. This solution is effectively passing the problem to application developers instead. At the cost of storing multiple values for the same key, we can provide the client with conflicting values and their timestamps. With this solution, Lamport timestamps are not very useful, since they do not show causality between concurrent events.

To improve on Lamport clocks, vector clocks can be used. Vector clocks contain a Lamport timestamp for each node in the system. They show exactly which previous transactions may have affected a transaction, across the whole system. For example, a client may know which node handled a previous transaction, and vector clocks would make it clear which of several conflicting values would be consistent with that previous transaction, at the application level.

I may explore this method as an extension.

\end{itemize}

- Variations to implement different consistency guarantees from \cite{terry2013}

% Other Terry paper

- Compare to other systems (Chubby \cite{27897}, Spanner, BigTable, Dynamo, etc.)

\section*{System Limitations}

My design has a number of important limitations, which are summarised here.

\begin{itemize}
\item
The set of database nodes is fixed. Additional nodes cannot be added to the system, and existing ones cannot be removed. In practice, the ability to change the set of nodes is useful for scaling a system while it is running, but doing so adds more complexity. Quorum assembly relies on the values $V_R$ and $V_W$, and their constraints which depend on the number of nodes $n$, so the number of nodes cannot be changed dynamically.

\item
Nodes cannot fail permanently. In 2PC, if a node fails, we need to wait for that node to become available again before allowing further writes, to ensure that the system remains consistent.

\item
The system may not remain consistent if, during a 2PC transaction, both the coordinator and another node in the quorum fail.

\item
If any database node's persistent store is irreversibly corrupted on failure, then consistency guarantees may be violated.

\end{itemize}

  - Justify whether limitations are reasonable in the real world \cite{imbriaco_2012}

  %- Justify these based on RAID, Reed-Solomon

\chapter{Implementation}
% 40%

\section{Quorum Assembly}

The main method for ensuring consistency in my system is quorum assembly. For a strongly consistent system, strict quorum assembly is needed. For eventual consistency, this will be modified to use a sloppy quorum method.

Given a system of $n$ nodes, we first have to define two values $V_R$ and $V_W$, which are the sizes of read and write quorums, respectively. At least $V_R$ nodes must be involved in every read transaction, and at least $V_W$ nodes must be involved in every write. In a strict quorum system, we also enforce the following constraints:

$$V_W > n / 2$$

$$V_R + V_W > n$$

The first constraint means that every value written to the database must be written to a majority of database nodes. The second constraint means that, for any read quorum, at least one node in the quorum will have the most recent version of each value stored. Where multiple conflicting values exist for the same key, we need Lamport timestamps to identify the most recent value.

Lamport timestamps are monotonically increasing integers, which indicate the order in which some events occur. If some event $A$'s timestamp is smaller than another event $B$'s, then $A$ happened before $B$.

In my system, each node stores a Lamport timestamp for each database key. Where different nodes have conflicting values for the same key, the one with the greater clock value is most recent.

In order to ensure Lamport clock values do not overflow, and thus to ensure they are monotonically increasing, my system will use 64 bit unsigned integers for Lamport clocks. A clock value is incremented each time the associated key-value pair is overwritten. Assuming a high throughput, with 1 transaction every 10 milliseconds writing to the same key, the time before the Lamport clock overflows will be $2^{64} \times 10 \cdot 10^{-3} = 1.84 \cdot 10^{16} \text{seconds}$. This is more than 5 billion years, so 64 bit timestamps should be adequate.

Building on the basic data store interface, Lamport clock values will be stored as part of the value. At the lower level, each value is actually the concatenation of a Lamport timestamp and the data being stored. In the case when a value is deleted, the concatenation of a timestamp and an empty byte array will be stored. This indicates that a value has been deleted from this node, which will be necessary for reads (for example, when a read quorum contains some nodes on which a value has been deleted, and some which still have a stale value), but does not violate the requirement of not storing null values in the low-level store.

The procedure for a read transaction is:

\begin{itemize}
  \item
  A node receives a read request from the client. This node shall be the coordinator.

  \item
  Assemble a quorum of at least $V_R$ nodes, and obtain a lock on each node in the quorum.

  \item
  The coordinator queries each node in the quorum with the given key.

  \item
  Each node returns the value it has stored, and the Lamport clock associated with the key, or says it has no value stored for the key.

  \item
  The coordinator identifies the value with the highest Lamport timestamp, and returns that value as the result.

  \item
  The coordinator releases all locks.

\end{itemize}

Note that this may reach a deadlock condition. Suppose there are multiple concurrent transactions, concurrently acquiring locks on nodes. This may reach a condition where every node is locked, but no coordinator has assembled a complete quorum. If latency was not an issue, we could avoid this by always acquiring locks in the same order, ordered by node IDs. This would require $O(V_W)$ RTTs. Since $V_W > n / 2$, this would add significant latency with a large number of nodes (eg. $RTT = 20$ ms, $V_W = 500$ means acquiring locks would take $2$ seconds). Note that on average half of the nodes involved are unavailable throughout those 2 seconds, so this would have a significant effect on availability.

There will also be a problem if the coordinator fails before it releases locks. This would leave nodes permanently locked, and effectively useless.

To fix both of these problems, each node should set a timer when its lock is acquired, and reset that timer each time it responds to a request from the coordinator. If the timer runs out, it should release its lock. If it subsequently receives a request from the coordinator, it should return an error. The coordinator, if it receives an error, should abort and retry the transaction.

Note that, since every node in a read quorum is locked, and given the constraint $V_R + V_W > n$, there cannot be concurrent read and write transactions. This imposes a happens-before relationship between each read transaction and every write transaction, so ensures that the value read is consistent. There may be concurrent read transactions; this has no effect on consistency, and will allow greater throughput.

The procedure for write transactions is similar to that for reads, but requires additional work to ensure atomicity. When a value is written, it must be either written to a full write quorum, or not written at all. This is achieved using an atomic commit protocol, 2 phase commit (2PC).

The write procedure is:

\begin{itemize}
  \item
  A node receives a write request from the client. This node shall be the coordinator.

  \item
  Assemble a quorum of at least $V_W$ nodes, and obtain a lock on each node in the quorum.

  \item
  The coordinator queries the existing value for the required key from each node in the quorum. Note that this is essentially a read transaction before a write transaction, which is why strict quorum is sometimes describe as ``read your own writes''

  \item
  Each node returns the value it has stored for the given key, and the Lamport clock associated with that key.

  \item
  The coordinator identifies the most recent timestamp associated with the key. Note that, given the constraint $V_W > n / 2$, this must be the most recent write for the key. The coordinator increments the greatest timestamp to get the timestamp for the new write.

  \item
  The coordinator initiates 2PC with all the nodes in the quorum, to write the new value and the new Lamport timestamp.

  \item
  The coordinator releases all locks.

\end{itemize}

The same deadlock condition as with read transactions applies here, so we will use the same timer system for pre-emption.

\section{Two-Phase Commit (2PC)}

In 2PC, the coordinator begins by sending the transaction to each node in the quorum, as well as sending a list of nodes involved in the transaction.

Each node should then execute the transaction, writing the new value to persistent storage but not yet committing. It should save a new vector clock value with the new value, which is the merge of its existing vector for the key, and the vector clock from the coordinator. It should then respond to the coordinator with a yes vote, and a copy of its new vector clock for the key. In case of any failure, it should respond with a no vote, and can cancel the transaction.

If the coordinator receives a yes vote from every node, it should:

\begin{itemize}
  \item
  Send a commit message to each node.

  \item
  Wait for an acknowledgement from each node.

  \item
  When it receives an acknowledgement from every node, commit the transaction to its own disk.

\end{itemize}

In the case that the coordinator does not receive an acknowledgement from every node, it should repeatedly send commit messages until it does so. This is one drawback of 2PC: it is a blocking protocol. Until all nodes involved have acknowledged, a write transaction cannot be completed. Note that all nodes involved are locked throughout this time; given that concurrent writes are not allowed, this will affect the availability of the system, but it does provide consistency.

If the coordinator doesn't receive a yes vote from every node (either at least one no vote, or a response times out), it should send a rollback message to all nodes.

In case of the coordinator failing, all other nodes in the transaction will timeout. In this case, since they all know the identifiers of all nodes involved in the transaction, the node with the lowest identifier becomes a new coordinator. The new coordinator queries all other nodes for their votes. In case any node voted no, it should be aborted. Otherwise, the transaction can be completed. When the coordinator recovers, it can determine from the other nodes whether or not the transaction was committed.

2PC is tolerant of most failure scenarios.

\begin{itemize}
  \item
  In the case of a node (or several nodes) other than the coordinator failing before sending a yes vote, the coordinator will abort the transaction.

  \item
  In the case of a node other than the coordinator failing after sending a yes vote, the failed transaction will be stored persistently on that node, so the node will be able to recover.

  \item
  In the case of the coordinator failing, all other nodes involved in the transaction can communicate to decide whether or not to abort. The transaction will be stored persistently on the coordinator node, so the coordinator can recover in the same way as any other node failing after voting yes.

\end{itemize}

A limitation of this is that it is not tolerant of data loss on failure, for example due to disk failure. This is a limitation of my system. In the real world, each node could store data on multiple disks in a RAID array, making the chance of data loss negligible. In case of total loss of database nodes, data could still be recovered provided at least half of the database nodes are unaffected, although at the cost of availability.

Another issue is the case of simultaneous failure of both the coordinator and another node. In this case, the remaining nodes could try to recover, but could not know whether the second failed node voted yes or no. This is a limitation of my system. As an extension, I may modify the system to use three-phase commit (3PC), which addresses this problem.

\section{Sloppy Quorum}

Sloppy quorum is a modification to the strict quorum system, which does not provide strong consistency guarantees. The procedure for transactions is the same as before, but we remove the constraint $V_R + V_W > n$.

This means that a read transaction may not return the most recent value for the requested key; it may return a stale value. The benefit is that more read transactions can occur concurrently, which will allow a greater throughput of transactions, and the system can remain available for read after a larger number of node failures: as long as at least $V_R$ nodes are available, read transactions can still occur.

In order to provide eventual consistency, we need to change the system more. In an eventually consistent system, if there are no write transactions, the whole system should reach a consistent state after some amount of time. This means that every read transaction should eventually return the most recently written value for each key. Having removed the constraint on $V_R$, this means that values should eventually be written to at least $n - V_R + 1$ nodes.

In order to achieve this, I will add an additional mechanism for sharing values between database nodes. Each write transaction has a coordinator, and that coordinator will be responsible for ultimately propagating the write to at least $n - V_R + 1$ nodes. My system assumes that the set of nodes is fixed, and there is no requirement for the time to reach consistency, so the coordinator can resume this task after failure and recovery without issue.

For each database key, each node should store an integer $x$ representing the number of nodes which have definitely received the value stored.  When a value is written by a transaction coordinated by another node, that value's $x$ can be set to $n$; although not true, the propagation of that value is another node's responsibility. When a node coordinates a write transaction, it should set $x$ to the number of nodes in the write quorum.

Each node then needs a background process to continually propagate values for which $x$ is smaller than $n - V_R + 1$. This could be done by initiating write transaction, but doing so would take much more time, and the consistency guarantee is not required.

Instead, a node can send a lightweight write message to other nodes. When a lightweight write message is received, a node should compare the given key, value and timestamp to what it has stored. If the value received is more recent than that stored, it should update its stored value and reply. Otherwise, it should reply with its more recent value and timestamp. When receiving a response from a lightweight write, a node can either increment $x$ for the relevant key, or store a more recent value in its store.

In case of failure of a lightweight write, there is no problem. The guarantees provided by full write transactions are still the same, and lightweight transactions can be retried later to eventually achieve consistency.

\section{Data Storage}

Each database node in the system needs its own key-value store. This will be built as a module independently of all distributed components of the system, and can be tested as a stand-alone module. Since the main focus of this project is distributed systems, and I expect the performance bottleneck to be network latency, this module is designed preferring simplicity over optimisation. As an extension, I may explore more efficient data structures for storage.

The datastore is built on top of a Unix-like file system. The particular file system does not matter, provided modification to a file descriptor (eg. renaming a file) is an atomic operation.

Data will be stored as binary files. The interface says that keys and values are byte arrays, which may not contain the null character. Keys and values will be written to disk as binary, using the null character (\verb|\0|) as a delimiter. The content of any valid file will match the format:

\verb|(Key \0 Value \0)*|

Also, a file must contain at most one occurrence of any key. Given this, any file can be uniquely deserialised to a map from byte array to byte array.

There is no requirement for any ordering of keys in a file, so the most efficient way to lookup a key is a linear search, which will take $O(n)$ time when there are $n$ key-value pairs stored. To mitigate this, data will be split between multiple files, based on a hash of the key.

A simple hash function could use the prefix of the key: the first 2 bytes, for example. This would divide data uniformly if keys are random, but may group many values together if their keys are similar (which is entirely determined by the application programmer).

Instead, I will use MD5. While not cryptographically secure, MD5 is a relatively fast hashing algorithm. Each file in the datastore will correspond to the first 2 bytes of an MD5 hash. This should divide data uniformly, assuming that keys are not chosen with intent to maximise the number of collisions. The name of each file will be the 2 byte prefix, encoding as a hexadecimal string to avoid use of invalid characters in filenames. This will also not require the filenames to be case sensitive in the underlying file system.

The most important method for the datastore to provide is atomic writes. This is achieved by writing to a shadow data structure.

My system does not allow concurrent write transactions, and each write modifies 1 key-value pair. This means that each transaction modifies one data file, and all writes are sequential. The write procedure for modifying a file $f$ is:

\begin{itemize}
\item
Create a new file $g$.

\item
Write data to $g$, which will be the contents of $f$, modified based on the transaction's parameters.

\item
Wait for a commit instruction.

\item
If a commit instruction is received, change the file descriptor $f$ to point at $g$ (\verb|mv g f|).

\item
If, instead, a rollback instruction is received, delete $g$.

\end{itemize}

% TODO: rewrite: Hash table on disk

%  - But many nodes sharing one disk won't work, so

%  - Trie in memory, with added delay

\section{Leadership Election}

With $n$ nodes, my system constrains the write quorum size $V_W$ with$V_W > n / 2$. This means that there can never be concurrent writes; if two nodes each simultaneously attempt to assemble a quorum for a write transaction, they cannot both succeed at the same time. This means there has to be a mechanism to avoid a deadlock condition. I implemented a timeout, which aborts a transaction if assembling a quorum takes too much time; one of the conditions for deadlock is no preemption, so a deadlock cannot occur.

While this recovers from the deadlock, usually both transactions fail in this case, and often a large number of nodes are locked until the transactions are aborted. This has a significant effect on the system's throughput. My system allows any database node to receive client requests and coordinate transactions. Since attempted concurrent writes are expensive, I built a mechanism to minimise the number of instances when this occurs. This is based on a ring election algorithm.

The idea is, since there cannot be concurrent writes, make a single node responsible for coordinating all write transactions. Rather than rely on a single node (and be unavailable for writes when the node is unreachable), a node is elected. Note that attempted concurrent writes affect performance rather than correctness, so my system can tolerate no consensus on the current leader (different nodes disagree on the current leader), although this should be avoided.

All nodes are considered part of a virtual ring. This is defined based on node IDs, since these are assigned sequentially. If there are $N$ nodes in total, each node $n$ is adjacent to nodes $(n + 1) \% N$ and $(n - 1) \% N$. There is a token message continually forwarded around the ring containing a list of node IDs. When each node receives the token, it does the following:

\begin{itemize}
\item
Send an acknowledge (ACK) message to the sender (the previous node in the ring).

\item
Add its own ID to the token, if not already present.

\item
Pick the current leader as the highest ID listed in the token, updating its local record of the leader ID.

\item
Forward the token to the next node in the ring.

\item
If no ACK is received after a timeout, remove the next node's ID from the token (if present), and forward the token to the node after next.

\end{itemize}

% TODO: check the code actually does this

This means that an unreachable node will be detected after at most the time taken for the token to traverse the ring, plus the timeout length. After another traversal of the ring, every node will be aware of the new leader.

The token may be lost, if a node fails before forwarding it. To fix this, any node which does not receive the token for some time should create a new token. Until a new token has traversed the ring, nodes will disagree on the current leader, but will reach consensus after one traversal (unless the token is lost again). This is acceptable for my system.

Since any node may create a token, the system may reach a state when there are many tokens. This is not a problem, but may cause problems if there are too many tokens in use, each using network capacity and processing time across the system. To fix this, each node has a rate-limiter. Each node enforces a minimum time between forwarding 2 tokens. Any tokens to be sent before the minimum time has elapsed are discarded, limiting the total number of tokens in use.

% TODO: some data to justify the benefit of this, compare to bully

\section{Thread Confinement}

% TODO: citation about thread confinement

My database system, like all distributed systems, uses a lot of concurrency, both between separate database nodes and clients, and within each node. Building concurrency systems requires a lot of work to ensure thread-safety.

My system is built in Go, which provides some helpful primitives for concurrent programming: goroutines and channels.

Goroutines are similar to threads. Rather than using OS-level scheduling, the Go runtime has its own scheduler. Goroutines, unlike normal threads, have dynamically-sized stacks.

Typically, threads have a stack size around 1MB. This means that the number of active threads is limited by memory usage. Using a smaller stack allows more threads, but limits the number of stack frames before a stack overflow error. Using dynamically-sized stacks, the number of active goroutines can be much larger.

Channels in Go are essentially thread-safe queue structures. These are ideal for producer-consumer patterns. Enqueue operations on a channel block if the channel is full, and dequeue operations block if the channel is empty.

Within each database node, my system uses a thread confinement pattern to avoid deadlock and race conditions. This is based on a Go idiom: ``Do not communicate by sharing memory; instead, share memory by communicating.'' The state of each node belongs to a single goroutine, and cannot be read or modified directly by any other goroutine. \cite{effective}

Each database node essentially receives messages from the network, and processes them. How it responds to a message depends on a state machine. Based on this, it may send messages to other nodes or clients, change state and modify its local data store (or several or node of those). Importantly, some operations, such as accessing the datastore, require waiting for I/O.

The node's local state machine is owned by a single goroutine responsible for the main loop. This loop must not block for a prolonged period time. Other goroutines within the node are responsible for blocking operations, including setting timers. When a transaction times out, for example, the goroutine responsible cannot update the main state machine; instead, it sends a message to the main loop, using a channel. The main loop receives the message and responds appropriately. Importantly, only the main loop can access the state machine, so there can be no race conditions, without using any locks. Care must be taken to ensure the main loop cannot block, but I found this easier in practice than managing locks everywhere.

\section{Out-of-Order Delivery}

Any message sent over a network has some unknown and unbounded latency (really unbounded \cite{imbriaco_2012}). This means that messages may be delivered out-of-order: if a node $A$ sends several messages to node $B$, the order in which they are sent is not always the order in which they arrive. This can cause difficult problems.

What if a node is sent a lock request, then an unlock request very soon after? % TODO: diagram

If the unlock arrives before the lock, the node may become locked forever.

To fix this, each node stores all transaction IDs for which it has received an unlock request. If it subsequently receives a lock request with an already-seen ID, ignore it.

This leads to each node accumulating a record of every transaction ever, so make it soft state.

\section{Test Framework}

% TODO: rewrite this a lot

My system will be built so that it interfaces closely with my test framework, using my RPC system. This will provide an ideal environment for integration testing and evaluating the system's performance. The architecture is based on two of Go's concurrency primitives: goroutines and channels.

Goroutines are similar to threads. Rather than using OS-level scheduling, the Go runtime has its own scheduler. Goroutines, unlike normal threads, have dynamically-sized stacks. Typically, threads have a stack size around 1MB. This means that the number of active threads is limited by memory usage. Using a smaller stack allows more threads, but limits the number of stack frames before a stack overflow error. Using dynamically-sized stacks, the number of active goroutines can be much larger.

Channels in Go are essentially thread-safe queue structures. These are ideal for producer-consumer patterns. Consumers can easily poll the queue, blocking until a value is available. My design uses channels to simulate network links.

Each database node will run as its own goroutine. The system will support a fixed number of nodes, so each node will be identified by a unique integer. These will be assigned sequentially and remain constant, so they can be used as addresses in the simulated network.

For each database node, there will be two channels: one for incoming messages, and one for outgoing messages. A message may be a request from a (simulated) external client, a response to such a request, or a message used to coordinate nodes in the system. A message has 3 fields: source and destination addresses (integers), and a payload, the structure of which depends on the type of message. In order to handle a message, the network simulator only needs to inspect the source and destination addresses.

Supporting each database node, there will be an additional goroutine responsible for delivering its outgoing messages. This will use the following algorithm:

\begin{lstlisting}
while true:
    message = outgoingMessages.poll() // Blocking deque

    // Chance of packet loss, based on a given parameter
    if (uniform random value in range [0,1]) < x:
        continue

    // Random latency
    delay = (normal random value, for given mean and variance)
    sendAfterDelay(message, delay)
\end{lstlisting}

The \verb|sendAfterDelay| method spawns a new goroutine, which sleeps for the given time, then appends the message to the recipient's incoming queue. This means that the main loop will not block, so later messages will be delivered without uncontrolled delay.

The main routine will be responsible for simulating clients. This includes generating requests, sending these requests to random database nodes, and recording responses. For each request, it should record the time from request to response (if a response was received). If a request times out without a response, this should also be recorded.

Once all requests have either timed out or been responded to, the main routine will terminate (thus halting the whole system). By configuring the number and type of tests and recording responses (as well as configuring the network properties, as described above), this can be used for both integration testing and evaluating the system's performance.

% TODO: diagram

\chapter{Evaluation}
% 20% (with conclusions)

General test conditions \cite{nunemaker}

Strict Quorum

- Is the output consistent? How is this tested?

- Performance with difference quorum sizes

- Measured with and without retries, with and without node failures

- Comment on how common node failures are \cite{45855}

- Zoom in on particular test cases to measure performance over time, in detail

- In particular, consider total failure cases

Sloppy Quorum

- Same as above (availability)

- Measure time to convergence (consistency)

What Ifs?

- How are results affected by different transaction sizes?

- What if the distance (latency) between different nodes is different?

- What if we use finer locks (for each key), rather than global locking?

Other Consistency Guarantees?

- Implement and evaluate simple variations from Terry \cite{terry2013}

\chapter{Conclusions}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% the bibliography
\addcontentsline{toc}{chapter}{Bibliography}
\bibliography{refs}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% the appendices
\appendix
%
%\chapter{Latex source}
%
%\section{diss.tex}
%{\scriptsize\verbatiminput{diss.tex}}
%
%\section{proposal.tex}
%{\scriptsize\verbatiminput{proposal.tex}}
%
%\chapter{Makefile}
%
%\section{makefile}\label{makefile}
%{\scriptsize\verbatiminput{makefile.txt}}
%
%\section{refs.bib}
%{\scriptsize\verbatiminput{refs.bib}}

\chapter{Project Proposal}
%\addcontentsline{toc}{chapter}{Project Proposal}

\input{propbody.tex}

\end{document}
